{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import imagearchive\n",
    "\n",
    "import imagearchive.utils\n",
    "from imagearchive.config import setup_directories, setup_database_engine\n",
    "from imagearchive.schema import Archive, Platform, Document, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest, data, output = setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Directory(abspath='/home/colton/images/ingest'),\n",
       " Directory(abspath='/home/colton/images/data'),\n",
       " Directory(abspath='/home/colton/images/output'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest, data, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m/home/colton/images/ingest\u001b[00m\r\n",
      "└── \u001b[36m2020-05-08-image-archive-paper-documentation\u001b[00m\r\n",
      "    ├── \u001b[32marchive_metadata.csv\u001b[00m\r\n",
      "    ├── \u001b[36mdatabase-ontology\u001b[00m\r\n",
      "    │   ├── \u001b[32mdocument_metadata.csv\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-131218.png\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-131241.png\u001b[00m\r\n",
      "    │   └── \u001b[33mScreenshot_20200508-131316.png\u001b[00m\r\n",
      "    ├── \u001b[36mnsf-proposal\u001b[00m\r\n",
      "    │   ├── document_metadata.tsv\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-130403.png\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-130428.png\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-130519.png\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-130554.png\u001b[00m\r\n",
      "    │   ├── \u001b[33mScreenshot_20200508-130724.png\u001b[00m\r\n",
      "    │   └── \u001b[33mScreenshot_20200508-130902.png\u001b[00m\r\n",
      "    ├── \u001b[36moo-design\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1320_p001.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1320_p003.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1322_p001.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1323_p001.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1323_p002.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p001.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p003.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p004.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p005.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p006.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[33m20200508T1324_p007.jpg\u001b[00m\r\n",
      "    │   ├── \u001b[36mdomain-model\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124705874.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124712918.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124718978.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124727564.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124738007.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124741629.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124745794.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124750468.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124757541.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124801621.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124809143.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124815128.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124821721.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124826535.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124831090.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124834664.jpg\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mIMG_20200508_124910814.jpg\u001b[00m\r\n",
      "    │   │   └── \u001b[32mnested_metadata_to_overwrite_platform_and_document.csv\u001b[00m\r\n",
      "    │   └── \u001b[32mplatform_and_document_metadata.csv\u001b[00m\r\n",
      "    ├── \u001b[36mtalk-slides\u001b[00m\r\n",
      "    │   ├── \u001b[36mcu-talk\u001b[00m\r\n",
      "    │   │   ├── \u001b[32marbitrary_filename.csv\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mScreenshot_20200508-131000.png\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mScreenshot_20200508-131017.png\u001b[00m\r\n",
      "    │   │   ├── \u001b[33mScreenshot_20200508-131034.png\u001b[00m\r\n",
      "    │   │   └── \u001b[33mScreenshot_20200508-131050.png\u001b[00m\r\n",
      "    │   └── \u001b[36mncar-talk\u001b[00m\r\n",
      "    │       ├── \u001b[32manother_arbitrary_filename.csv\u001b[00m\r\n",
      "    │       ├── \u001b[33mScreenshot_20200508-131429.png\u001b[00m\r\n",
      "    │       ├── \u001b[33mScreenshot_20200508-131439.png\u001b[00m\r\n",
      "    │       ├── \u001b[33mScreenshot_20200508-131451.png\u001b[00m\r\n",
      "    │       ├── \u001b[33mScreenshot_20200508-131504.png\u001b[00m\r\n",
      "    │       └── \u001b[33mScreenshot_20200508-131513.png\u001b[00m\r\n",
      "    └── \u001b[36mworkflow\u001b[00m\r\n",
      "        ├── \u001b[33m20200508T1325_p001.jpg\u001b[00m\r\n",
      "        ├── \u001b[33m20200508T1325_p003.jpg\u001b[00m\r\n",
      "        ├── \u001b[33m20200508T1325_p005.jpg\u001b[00m\r\n",
      "        └── document_metadata_for_these_images_in_tabbed_format.tsv\r\n",
      "\r\n",
      "9 directories, 57 files\r\n"
     ]
    }
   ],
   "source": [
    "# if you have tree installed, we can see the directory tree to be ingested\n",
    "!tree $ingest.abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module config should also import exiftool as a submodule\n",
    "imagearchive.config.exiftool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/colton/fy/20/rda-image-archive/imagearchive/utils.py(148)get_normalized_catalog()\n",
      "-> get_normalized_catalog(child, overwrite=overwrite)\n",
      "(Pdb) a\n",
      "data_dir = '/home/colton/images/ingest'\n",
      "overwrite = False\n",
      "(Pdb) l\n",
      "143  \t        # Recurse down by calling `get_normalized_catalog` for each child.\n",
      "144  \t        # We reserve the key 'contents' for inclusion of lists of child\n",
      "145  \t        # dictionaries. The key 'contents' should appear 0 or 1 times in\n",
      "146  \t        # each child dictionary.\n",
      "147  \t        normalized_catalog['contents'] = [\n",
      "148  ->\t                get_normalized_catalog(child, overwrite=overwrite)\n",
      "149  \t                for child in children\n",
      "150  \t                if not os.path.basename(child).startswith(\".\")]\n",
      "151  \t        # TODO Add some type of \"ignore\" capabilities.\n",
      "152  \t        # For now, just ignore hidden files.  2019-11-21\n",
      "153  \t\n",
      "(Pdb) a\n",
      "data_dir = '/home/colton/images/ingest'\n",
      "overwrite = False\n",
      "(Pdb) children\n",
      "<map object at 0x7fcf2a3f38d0>\n",
      "(Pdb) list(children)\n",
      "*** Error in argument: '(children)'\n",
      "(Pdb) children\n",
      "<map object at 0x7fcf2a3f38d0>\n",
      "(Pdb) for c in children: print(c)\n",
      "/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "normalized_catalog=imagearchive.utils.get_normalized_catalog(ingest.abspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = imagearchive.utils.unnormalize_catalog(normalized_catalog)\n",
    "# We flatten the normalized catalog. \n",
    "# Each file in the data directory \"has its own entry\" in this catalog.\n",
    "# We'll eventually ignore non-image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': '/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation/archive_metadata.csv',\n",
       "  'media_type': 'text/plain'},\n",
       " {'file_path': '/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation/database-ontology/Screenshot_20200508-131218.png',\n",
       "  'media_type': 'image/png',\n",
       "  'uuid': 'b5841be8916b11eab94d08119645fa1c'},\n",
       " {'file_path': '/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation/database-ontology/Screenshot_20200508-131241.png',\n",
       "  'media_type': 'image/png',\n",
       "  'uuid': 'b5b5b9e6916b11eab94d08119645fa1c'},\n",
       " {'file_path': '/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation/database-ontology/Screenshot_20200508-131316.png',\n",
       "  'media_type': 'image/png',\n",
       "  'uuid': 'b5e41a1c916b11eab94d08119645fa1c'},\n",
       " {'file_path': '/home/colton/images/ingest/2020-05-08-image-archive-paper-documentation/database-ontology/document_metadata.csv',\n",
       "  'media_type': 'text/plain'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_timestamped_catalog(catalog, out)\n",
    "# We write this version of the metadata catalog to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = read_timestamped_catalog(out)\n",
    "# We read in the most recent version of the metadata catalog from the out directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename images by `uuid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elementary_family = [c for c in catalog if c['media_type'].startswith(\"image\")]\n",
    "# We create a list of all the entries in the catalog that are image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# We'll perform some file renames between the data directory and the out directory.\n",
    "\n",
    "# We move all the images in the catalog to the output directory.\n",
    "for member in elementary_family:\n",
    "    os.rename(member['file_path'], os.path.join(out, member['uuid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick up catalog with `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(catalog)\n",
    "df = df[df['media_type'].str.contains(\"image\")] \n",
    "# we only want to keep track of image files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter `DataFrame` for archives, platforms, documents, and images to insert\n",
    "into DB `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_df = df.filter(regex=(\"^archive\"))\n",
    "arc_df = arc_df.drop_duplicates()\n",
    "arc_df.rename(columns=lambda x: re.sub('archive.','',x), inplace=True)\n",
    "arc_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_df = df.filter(regex=(\"^platform\"))\n",
    "plt_df = plt_df.drop_duplicates()\n",
    "plt_df.rename(columns=lambda x: re.sub('platform.','',x), inplace=True)\n",
    "plt_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.concat(\n",
    "    [df.filter(regex=(\"^document\")), \n",
    "     df.filter(items=[\"archive.host_country\", \"archive.name\"]),\n",
    "     df.filter(items=[\"platform.host_country\", \"platform.name\"])\n",
    "    ], axis=1\n",
    ").drop_duplicates()\n",
    "doc_df.rename(columns=lambda x: re.sub('document.', '', x), inplace=True)\n",
    "doc_df.fillna(\"\", inplace=True) # avoid NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## declare and persist tables in `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i scripts/tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('mysql+mysqlconnector://user:pass@rda-db.ucar.edu/images')\n",
    "# engine = create_engine('mysql+pymysql://user:pass@localhost/images')\n",
    "# TODO read defaults extra file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop_all(engine) # clean out the DB\n",
    "metadata.create_all(engine) # reinitialize the canonical schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect() # let's start working with these tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata insertion for archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = insert(archive)\n",
    "rp = connection.execute(ins, arc_df.to_dict('records'))\n",
    "# throws integrity error if run twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select([archive])\n",
    "rp = connection.execute(s)\n",
    "for arc in rp:\n",
    "    print(arc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata insertion for platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = insert(platform)\n",
    "rp = connection.execute(ins, plt_df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select([platform])\n",
    "rp = connection.execute(s)\n",
    "for plt in rp:\n",
    "    print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata insertion for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import and_\n",
    "\n",
    "def get_archive_fk(doc_dict): # add error handling\n",
    "    s = select([archive.c.archive_id])\n",
    "    s = s.where(and_(\n",
    "        archive.c.name == doc_dict['archive.name'],\n",
    "        archive.c.host_country == doc_dict['archive.host_country']\n",
    "    ))\n",
    "    s = s.limit(1) # should be unique anyways\n",
    "    rp = connection.execute(s)\n",
    "    result = rp.scalar() # is the parent id\n",
    "    return result\n",
    "\n",
    "def get_platform_fk(doc_dict): # add error handling\n",
    "    s = select([platform.c.platform_id])\n",
    "    s = s.where(and_(\n",
    "        platform.c.name == doc_dict['platform.name'],\n",
    "        platform.c.host_country == doc_dict['platform.host_country']\n",
    "    ))\n",
    "    s = s.limit(1) # should be unique anyways\n",
    "    rp = connection.execute(s)\n",
    "    result = rp.scalar() # is the parent id\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_dict in doc_df.to_dict('record'):\n",
    "    arc_id = get_archive_fk(doc_dict)\n",
    "    plt_id = get_platform_fk(doc_dict)\n",
    "    for key in [\n",
    "        'archive.host_country',\n",
    "        'archive.name',\n",
    "        'platform.host_country',\n",
    "        'platform.name'\n",
    "    ]:\n",
    "        doc_dict.pop(key)\n",
    "    ins = insert(document)\n",
    "    rp = connection.execute(ins,\n",
    "            doc_dict,\n",
    "            archive_id = arc_id,\n",
    "            platform_id = plt_id\n",
    "    )\n",
    "# throws an integrity error if run twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select([document.c.id_within_archive_type, document.c.id_within_archive, document.c.contact_person])\n",
    "s = s.where(document.c.start_date.between(\"1900-01-01\", \"2000-01-01\"))\n",
    "rp = connection.execute(s)\n",
    "for res in rp:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select([document.c.id_within_archive_type, document.c.id_within_archive, document.c.contact_person])\n",
    "s = s.where(document.c.start_date.between(\"1800-01-01\", \"1900-01-01\"))\n",
    "rp = connection.execute(s)\n",
    "for res in rp:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata insertion for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_fk(img_dict):\n",
    "    s = select([document.c.document_id])\n",
    "    s = s.where(and_(\n",
    "        document.c.id_within_archive == img_dict['document.id_within_archive'],\n",
    "        document.c.id_within_archive_type == img_dict['document.id_within_archive_type']\n",
    "    ))\n",
    "    s = s.limit(1) # should be unique anyways\n",
    "    rp = connection.execute(s)\n",
    "    result = rp.scalar() # is the parent id\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = df.filter(items=[\"uuid\",\"media_type\",\"document.id_within_archive\",\"document.id_within_archive_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dict in img_df.to_dict('record'):\n",
    "    doc_id = get_document_fk(img_dict)\n",
    "    for key in [\"document.id_within_archive\",\"document.id_within_archive_type\"]:\n",
    "        img_dict.pop(key)\n",
    "    img_dict['document_id'] = doc_id\n",
    "    ins = insert(image, img_dict)\n",
    "    print(ins.compile().params)\n",
    "    rp = connection.execute(ins, img_dict)    \n",
    "# throws an integrity error if run twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieval of images by uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = select([image.c.uuid, image.c.media_type])\n",
    "s = s.order_by(image.c.uuid)\n",
    "rp = connection.execute(s)\n",
    "\n",
    "for img in rp:\n",
    "    print(os.path.join(out, img.uuid), img.media_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsetting by date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [image.c.uuid, image.c.media_type, \n",
    "           document.c.start_date, document.c.standardized_region_list]\n",
    "\n",
    "twentieth_century = select(columns)\n",
    "twentieth_century = twentieth_century.select_from(\n",
    "    image.join(document)).where(\n",
    "    document.c.start_date.between(\"1900-01-01\", \"1999-12-31\"))\n",
    "\n",
    "rp = connection.execute(twentieth_century).fetchall()\n",
    "\n",
    "for img in rp:\n",
    "    display(Image(\n",
    "        filename=os.path.join(out, img.uuid),\n",
    "        format=img.media_type.replace(\"image/\",\"\")\n",
    "    ))\n",
    "    for key in img.keys():\n",
    "        print('{:>20}: {}'.format(key, img[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [image.c.uuid, image.c.media_type, \n",
    "           document.c.start_date, document.c.standardized_region_list]\n",
    "\n",
    "nineteenth_century = select(columns)\n",
    "nineteenth_century = nineteenth_century.select_from(\n",
    "    image.join(document)).where(\n",
    "    document.c.start_date.between(\"1800-01-01\", \"1899-12-31\"))\n",
    "nineteenth_century = nineteenth_century.order_by(document.c.start_date)\n",
    "\n",
    "rp = connection.execute(nineteenth_century).fetchall()\n",
    "\n",
    "for img in rp:\n",
    "    display(Image(\n",
    "        filename=os.path.join(out, img.uuid),\n",
    "        format=img.media_type.replace(\"image/\",\"\")\n",
    "    ))\n",
    "    for key in img.keys():\n",
    "        print('{:>20}: {}'.format(key, img[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
